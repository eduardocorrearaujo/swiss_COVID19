{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f25e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import  LogNormal\n",
    "from ngboost.scores import LogScore\n",
    "from datetime import datetime, timedelta\n",
    "from get_data import build_lagged_features, compute_clusters, get_combined_data, get_updated_data\n",
    "from sqlalchemy import create_engine\n",
    "from loguru import logger\n",
    "engine = create_engine(\"postgresql://epigraph:epigraph@localhost:5432/epigraphhub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predictions(target_name, data, ini_date = '2020-03-01',split = 0.75, horizon_forecast = 14, maxlag=15):\n",
    "\n",
    "    target = data[target_name]\n",
    "\n",
    "    df_lag = build_lagged_features(copy.deepcopy(data), maxlag=maxlag )\n",
    "    \n",
    "    ini_date = max(df_lag.index[0],target.index[0], datetime.strptime(ini_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    df_lag = df_lag[ini_date:]\n",
    "    target = target[ini_date:]\n",
    "    target = target.dropna()\n",
    "    df_lag = df_lag.dropna()\n",
    "\n",
    "    # remove the target column and columns related with the day that we want to predict \n",
    "    df_lag = df_lag.drop(data.columns, axis = 1)\n",
    "\n",
    "    # targets \n",
    "    targets = {}\n",
    "\n",
    "    for T in np.arange(1,horizon_forecast+1,1):\n",
    "        if T == 1:\n",
    "            targets[T] = target.shift(-(T - 1))\n",
    "        else:\n",
    "            targets[T] = target.shift(-(T - 1))[:-(T - 1)]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_lag, target, train_size=split, test_size=1 - split, shuffle=False)\n",
    "    \n",
    "    if np.sum(target) > 0.0: \n",
    "\n",
    "        idx = pd.period_range(start=df_lag.index[0], end=df_lag.index[-1], freq='14D')\n",
    "        \n",
    "        idx = idx.to_timestamp()\n",
    "        \n",
    "        # predictions \n",
    "        preds5 = np.empty((len(idx), horizon_forecast))\n",
    "        preds50 = np.empty((len(idx), horizon_forecast))\n",
    "        preds95 = np.empty((len(idx), horizon_forecast))\n",
    "\n",
    "\n",
    "        for T in range(1, horizon_forecast + 1):\n",
    "\n",
    "            tgt = targets[T][:len(X_train)]\n",
    "            \n",
    "            i = 0\n",
    "            \n",
    "            while i < len(tgt):\n",
    "                if tgt[i] <= 0:\n",
    "                    \n",
    "                    tgt[i] = 0.01\n",
    "                i = i+1\n",
    "                \n",
    "            \n",
    "            model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n",
    "                                natural_gradient=True,verbose=False, col_sample = 0.9, \n",
    "                                n_estimators=300,\n",
    "            learning_rate=0.1,\n",
    "            validation_fraction=0.25,\n",
    "            early_stopping_rounds = 50)\n",
    "                \n",
    "            model.fit(X_train, tgt)\n",
    "            \n",
    "            pred = model.pred_dist(df_lag.loc[idx])\n",
    "\n",
    "            pred50 = pred.median()\n",
    "\n",
    "            pred5, pred95 = pred.interval(alpha = 0.95)\n",
    "\n",
    "            preds5[:, (T - 1)] = pred5\n",
    "            preds50[:, (T - 1)] = pred50\n",
    "            preds95[:, (T - 1)] = pred95\n",
    "\n",
    "\n",
    "        # transformando preds em um array\n",
    "        train_size = len(X_train)\n",
    "\n",
    "        y5 = preds5.flatten()\n",
    "        y50 = preds50.flatten()\n",
    "        y95 = preds95.flatten()\n",
    "\n",
    "        x= pd.period_range(start=df_lag.index[1], end=df_lag.index[-1], freq='D').to_timestamp()\n",
    "        \n",
    "        x = np.array(x)\n",
    "        \n",
    "        y5 = np.array(y5)\n",
    "        \n",
    "        y50 = np.array(y50)\n",
    "        \n",
    "        y95 = np.array(y95)\n",
    "        \n",
    "        target = targets[1]\n",
    "        \n",
    "        train_size = len(X_train)\n",
    "        \n",
    "        dif = len(x) - len(y5)\n",
    "            \n",
    "        if dif <0:\n",
    "            y5 = y5[:len(y5) + dif]\n",
    "            y50 = y50[:len(y50) + dif]\n",
    "            y95 = y95[:len(y95) + dif]\n",
    "            \n",
    "        df_pred = pd.DataFrame()\n",
    "        df_pred['target'] = target[1:]\n",
    "        df_pred['date'] = x\n",
    "        df_pred['lower'] = y5\n",
    "        df_pred['median'] = y50\n",
    "        df_pred['upper'] = y95\n",
    "        df_pred['train_size'] = [train_size]*len(df_pred)\n",
    "        df_pred['canton'] = [target_name[-2:]]*len(df_pred)\n",
    "\n",
    "    else:\n",
    "        x= pd.period_range(start=df_lag.index[1], end=df_lag.index[-1], freq='D').to_timestamp()\n",
    "        \n",
    "        x = np.array(x)\n",
    "\n",
    "        df_pred = pd.DataFrame()\n",
    "        df_pred['target'] = target[1:]\n",
    "        df_pred['date'] = x\n",
    "        df_pred['lower'] = [0.0]*len(df_pred)\n",
    "        df_pred['median'] =[ 0.0]*len(df_pred)\n",
    "        df_pred['upper'] = [0.0]*len(df_pred)\n",
    "        df_pred['train_size'] = [len(X_train)]*len(df_pred)\n",
    "        df_pred['canton'] = [target_name[-2:]]*len(df_pred)\n",
    "\n",
    "    \n",
    "    return df_pred\n",
    "\n",
    "def make_single_prediction(target_curve_name, canton, predictors, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    '''\n",
    "    Function to make single prediction \n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params canton: canton of interest \n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    params title: If none the title will be: Hospitalizations - canton\n",
    "    params path: If none the plot will be save in the directory: images/hosp_{canton}\n",
    "    '''\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    if updated_data: \n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "\n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df = rolling_predictions(target_name, df,  ini_date = ini_date,split = 0.75,   horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    #fig = plot_predictions(target_curve_name, canton, target, train_size, x, y5,y50, y95, forecast_dates, forecasts5, forecasts50,forecasts95, title, path)\n",
    "    return df \n",
    "\n",
    "def make_predictions_all_cantons(target_curve_name,  predictors, cluster, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None):\n",
    "\n",
    "    '''\n",
    "    Function to make prediction for all the cantons\n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params target_curve_name: string to indicate the target column of the predictions\n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    \n",
    "    returns: Dataframe with the predictions for all the cantons\n",
    "    '''\n",
    "    \n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "  \n",
    "    df = get_combined_data(predictors, cluster, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    for canton in cluster:\n",
    "        # apply the model \n",
    "\n",
    "        target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "        horizon = 14\n",
    "        maxlag = 14\n",
    "\n",
    "        # get predictions and forecast \n",
    "            \n",
    "        df_pred = rolling_predictions(target_name, df,  ini_date = ini_date,split = 0.75,   horizon_forecast = horizon, maxlag=maxlag)\n",
    "            \n",
    "        df_all = pd.concat([df_all,df_pred])\n",
    "            \n",
    "    return df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
