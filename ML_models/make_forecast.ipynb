{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3434028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import  LogNormal\n",
    "from ngboost.scores import LogScore\n",
    "from datetime import datetime, timedelta\n",
    "from get_data import build_lagged_features, compute_clusters, get_combined_data, get_updated_data\n",
    "from sqlalchemy import create_engine\n",
    "from loguru import logger\n",
    "engine = create_engine(\"postgresql://epigraph:epigraph@localhost:5432/epigraphhub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48d5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predictions(target_name, data, ini_date = '2020-03-01',split = 0.75, horizon_forecast = 14, maxlag=15):\n",
    "\n",
    "    target = data[target_name]\n",
    "\n",
    "    df_lag = build_lagged_features(copy.deepcopy(data), maxlag=maxlag )\n",
    "    \n",
    "    ini_date = max(df_lag.index[0],target.index[0], datetime.strptime(ini_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    df_lag = df_lag[ini_date:]\n",
    "    target = target[ini_date:]\n",
    "    target = target.dropna()\n",
    "    df_lag = df_lag.dropna()\n",
    "\n",
    "    # remove the target column and columns related with the day that we want to predict \n",
    "    df_lag = df_lag.drop(data.columns, axis = 1)\n",
    "\n",
    "    # targets \n",
    "    targets = {}\n",
    "\n",
    "    for T in np.arange(1,horizon_forecast+1,1):\n",
    "        if T == 1:\n",
    "            targets[T] = target.shift(-(T - 1))\n",
    "        else:\n",
    "            targets[T] = target.shift(-(T - 1))[:-(T - 1)]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_lag, target, train_size=split, test_size=1 - split, shuffle=False)\n",
    "    \n",
    "    if np.sum(target) > 0.0: \n",
    "\n",
    "        idx = pd.period_range(start=df_lag.index[0], end=df_lag.index[-1], freq='14D')\n",
    "        \n",
    "        idx = idx.to_timestamp()\n",
    "        \n",
    "        # predictions \n",
    "        preds5 = np.empty((len(idx), horizon_forecast))\n",
    "        preds50 = np.empty((len(idx), horizon_forecast))\n",
    "        preds95 = np.empty((len(idx), horizon_forecast))\n",
    "\n",
    "\n",
    "        for T in range(1, horizon_forecast + 1):\n",
    "\n",
    "            tgt = targets[T][:len(X_train)]\n",
    "            \n",
    "            i = 0\n",
    "            \n",
    "            while i < len(tgt):\n",
    "                if tgt[i] <= 0:\n",
    "                    \n",
    "                    tgt[i] = 0.01\n",
    "                i = i+1\n",
    "                \n",
    "            \n",
    "            model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n",
    "                                natural_gradient=True,verbose=False, col_sample = 0.9, \n",
    "                                n_estimators=300,\n",
    "            learning_rate=0.1,\n",
    "            validation_fraction=0.25,\n",
    "            early_stopping_rounds = 50)\n",
    "                \n",
    "            model.fit(X_train, tgt)\n",
    "            \n",
    "            pred = model.pred_dist(df_lag.loc[idx])\n",
    "\n",
    "            pred50 = pred.median()\n",
    "\n",
    "            pred5, pred95 = pred.interval(alpha = 0.95)\n",
    "\n",
    "            preds5[:, (T - 1)] = pred5\n",
    "            preds50[:, (T - 1)] = pred50\n",
    "            preds95[:, (T - 1)] = pred95\n",
    "\n",
    "\n",
    "        # transformando preds em um array\n",
    "        train_size = len(X_train)\n",
    "\n",
    "        y5 = preds5.flatten()\n",
    "        y50 = preds50.flatten()\n",
    "        y95 = preds95.flatten()\n",
    "\n",
    "        x= pd.period_range(start=df_lag.index[1], end=df_lag.index[-1], freq='D').to_timestamp()\n",
    "        \n",
    "        x = np.array(x)\n",
    "        \n",
    "        y5 = np.array(y5)\n",
    "        \n",
    "        y50 = np.array(y50)\n",
    "        \n",
    "        y95 = np.array(y95)\n",
    "        \n",
    "        target = targets[1]\n",
    "        \n",
    "        train_size = len(X_train)\n",
    "        \n",
    "        dif = len(x) - len(y5)\n",
    "            \n",
    "        if dif <0:\n",
    "            y5 = y5[:len(y5) + dif]\n",
    "            y50 = y50[:len(y50) + dif]\n",
    "            y95 = y95[:len(y95) + dif]\n",
    "            \n",
    "        df_pred = pd.DataFrame()\n",
    "        df_pred['target'] = target[1:]\n",
    "        df_pred['date'] = x\n",
    "        df_pred['lower'] = y5\n",
    "        df_pred['median'] = y50\n",
    "        df_pred['upper'] = y95\n",
    "        df_pred['train_size'] = [train_size]*len(df_pred)\n",
    "        df_pred['canton'] = [target_name[-2:]]*len(df_pred)\n",
    "\n",
    "    else:\n",
    "        x= pd.period_range(start=df_lag.index[1], end=df_lag.index[-1], freq='D').to_timestamp()\n",
    "        \n",
    "        x = np.array(x)\n",
    "\n",
    "        df_pred = pd.DataFrame()\n",
    "        df_pred['target'] = target[1:]\n",
    "        df_pred['date'] = x\n",
    "        df_pred['lower'] = [0.0]*len(df_pred)\n",
    "        df_pred['median'] =[ 0.0]*len(df_pred)\n",
    "        df_pred['upper'] = [0.0]*len(df_pred)\n",
    "        df_pred['train_size'] = [len(X_train)]*len(df_pred)\n",
    "        df_pred['canton'] = [target_name[-2:]]*len(df_pred)\n",
    "\n",
    "    \n",
    "    return df_pred\n",
    "\n",
    "def make_single_prediction(target_curve_name, canton, predictors, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    '''\n",
    "    Function to make single prediction \n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params canton: canton of interest \n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    params title: If none the title will be: Hospitalizations - canton\n",
    "    params path: If none the plot will be save in the directory: images/hosp_{canton}\n",
    "    '''\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    if updated_data: \n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "\n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df = rolling_predictions(target_name, df,  ini_date = ini_date,split = 0.75,   horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    #fig = plot_predictions(target_curve_name, canton, target, train_size, x, y5,y50, y95, forecast_dates, forecasts5, forecasts50,forecasts95, title, path)\n",
    "    return df \n",
    "\n",
    "def make_predictions_all_cantons(target_curve_name,  predictors, cluster, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None):\n",
    "\n",
    "    '''\n",
    "    Function to make prediction for all the cantons\n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params target_curve_name: string to indicate the target column of the predictions\n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    \n",
    "    returns: Dataframe with the predictions for all the cantons\n",
    "    '''\n",
    "    \n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "  \n",
    "    df = get_combined_data(predictors, cluster, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    for canton in cluster:\n",
    "        # apply the model \n",
    "\n",
    "        target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "        horizon = 14\n",
    "        maxlag = 14\n",
    "\n",
    "        # get predictions and forecast \n",
    "            \n",
    "        df_pred = rolling_predictions(target_name, df,  ini_date = ini_date,split = 0.75,   horizon_forecast = horizon, maxlag=maxlag)\n",
    "            \n",
    "        df_all = pd.concat([df_all,df_pred])\n",
    "            \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3948040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 50s, sys: 6.96 s, total: 11min 57s\n",
      "Wall time: 12min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictors1 = ['cases', 'hosp', 'test']\n",
    "predictors2 = ['cases', 'hosp', 'test', 'hospcapacity']\n",
    "\n",
    "cluster1 = ['AG','AI',  'AR', 'BE', 'BL', 'BS', 'GL', 'LU', 'NW', 'OW', 'SG',\n",
    "        'SH', 'SO', 'SZ', 'TG', 'UR', 'ZG', 'ZH']\n",
    "cluster2 = ['FR', 'GE', 'GR', 'JU', 'NE', 'TI', 'VD', 'VS']\n",
    "\n",
    "target_curve_name = 'hosp'\n",
    "\n",
    "df2 = make_predictions_all_cantons(target_curve_name,  predictors1, cluster2, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772f8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('val_hosp_all_cantons1csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95be811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min, sys: 2.35 s, total: 5min 3s\n",
      "Wall time: 12min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictors1 = ['cases', 'hosp', 'test', 'hospcapacity']\n",
    "target_curve_name = 'ICU_patients'\n",
    "canton = 'GE'\n",
    "df = make_single_prediction(target_curve_name, canton, predictors1, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None, updated_data = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7b0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ml_validation_icu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54118623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>lower</th>\n",
       "      <th>median</th>\n",
       "      <th>upper</th>\n",
       "      <th>train_size</th>\n",
       "      <th>canton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.428571</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>36.783204</td>\n",
       "      <td>38.640374</td>\n",
       "      <td>40.591311</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.285714</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>32.825944</td>\n",
       "      <td>35.891307</td>\n",
       "      <td>39.242921</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.857143</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>31.498944</td>\n",
       "      <td>33.972813</td>\n",
       "      <td>36.640976</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.857143</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>29.922877</td>\n",
       "      <td>32.581478</td>\n",
       "      <td>35.476292</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.428571</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>28.604659</td>\n",
       "      <td>30.573797</td>\n",
       "      <td>32.678491</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>17.785714</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>10.782089</td>\n",
       "      <td>11.344816</td>\n",
       "      <td>11.936913</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>18.214286</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>14.019323</td>\n",
       "      <td>14.739362</td>\n",
       "      <td>15.496381</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>19.071429</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>12.038493</td>\n",
       "      <td>12.548592</td>\n",
       "      <td>13.080305</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>19.714286</td>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>13.042417</td>\n",
       "      <td>13.785270</td>\n",
       "      <td>14.570432</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>20.142857</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>14.471639</td>\n",
       "      <td>15.099405</td>\n",
       "      <td>15.754402</td>\n",
       "      <td>462</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target        date      lower     median      upper  train_size canton\n",
       "0    37.428571  2020-04-20  36.783204  38.640374  40.591311         462     GE\n",
       "1    35.285714  2020-04-21  32.825944  35.891307  39.242921         462     GE\n",
       "2    33.857143  2020-04-22  31.498944  33.972813  36.640976         462     GE\n",
       "3    31.857143  2020-04-23  29.922877  32.581478  35.476292         462     GE\n",
       "4    30.428571  2020-04-24  28.604659  30.573797  32.678491         462     GE\n",
       "..         ...         ...        ...        ...        ...         ...    ...\n",
       "611  17.785714  2021-12-22  10.782089  11.344816  11.936913         462     GE\n",
       "612  18.214286  2021-12-23  14.019323  14.739362  15.496381         462     GE\n",
       "613  19.071429  2021-12-24  12.038493  12.548592  13.080305         462     GE\n",
       "614  19.714286  2021-12-25  13.042417  13.785270  14.570432         462     GE\n",
       "615  20.142857  2021-12-26  14.471639  15.099405  15.754402         462     GE\n",
       "\n",
       "[616 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ml_validation_icu.csv')\n",
    "del df['Unnamed: 0']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a6b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_database(df, table_name):\n",
    "    df.to_sql(table_name, engine, schema= 'switzerland', if_exists = 'replace')\n",
    "\n",
    "save_to_database(df, 'ml_validation_icu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93012cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
