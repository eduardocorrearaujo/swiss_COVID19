{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d75f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import  LogNormal\n",
    "from ngboost.scores import LogScore\n",
    "from datetime import datetime, timedelta\n",
    "from get_data import build_lagged_features, compute_clusters, get_combined_data, get_updated_data\n",
    "from sqlalchemy import create_engine\n",
    "import lightgbm as lgb\n",
    "engine = create_engine(\"postgresql://epigraph:epigraph@localhost:5432/epigraphhub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14627cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import *\n",
    "#df = get_canton_data( 'hosp', ['GE'])\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82681d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.resample('D').mean()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a98793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19835d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predictions(target_name, data, ini_date = '2020-03-01',split = 0.75, horizon_forecast = 14, maxlag=15):\n",
    "\n",
    "    target = data[target_name]\n",
    "\n",
    "    df_lag = build_lagged_features(copy.deepcopy(data), maxlag=maxlag )\n",
    "    \n",
    "    ini_date = max(df_lag.index[0],target.index[0], datetime.strptime(ini_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    df_lag = df_lag[ini_date:]\n",
    "    target = target[ini_date:]\n",
    "    df_lag = df_lag.dropna()\n",
    "\n",
    "    # remove the target column and columns related with the day that we want to predict \n",
    "    df_lag = df_lag.drop(data.columns, axis = 1)\n",
    "\n",
    "    # targets \n",
    "    targets = {}\n",
    "\n",
    "    for T in np.arange(1,horizon_forecast+1,1):\n",
    "        if T == 1:\n",
    "            targets[T] = target.shift(-(T - 1))\n",
    "        else:\n",
    "            targets[T] = target.shift(-(T - 1))[:-(T - 1)]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_lag, target, train_size=split, test_size=1 - split, shuffle=False)\n",
    "\n",
    "    idx = pd.period_range(start=df_lag.index[0], end=df_lag.index[-1], freq='14D')\n",
    "    \n",
    "    idx = idx.to_timestamp()\n",
    "    \n",
    "    # predictions \n",
    "    preds5 = np.empty((len(idx), horizon_forecast))\n",
    "    preds50 = np.empty((len(idx), horizon_forecast))\n",
    "    preds95 = np.empty((len(idx), horizon_forecast))\n",
    "\n",
    "\n",
    "    for T in range(1, horizon_forecast + 1):\n",
    "\n",
    "        tgt = targets[T][:len(X_train)]\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(tgt):\n",
    "            if tgt[i] <= 0:\n",
    "                \n",
    "                tgt[i] = 0.01\n",
    "            i = i+1\n",
    "            \n",
    "        \n",
    "        model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n",
    "                             natural_gradient=True,verbose=False, col_sample = 0.9, \n",
    "                             n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        validation_fraction=0.25,\n",
    "        early_stopping_rounds = 50)\n",
    "            \n",
    "        model.fit(X_train, tgt)\n",
    "        \n",
    "        pred = model.pred_dist(df_lag.loc[idx])\n",
    "\n",
    "        pred50 = pred.median()\n",
    "\n",
    "        pred5, pred95 = pred.interval(alpha = 0.95)\n",
    "\n",
    "        preds5[:, (T - 1)] = pred5\n",
    "        preds50[:, (T - 1)] = pred50\n",
    "        preds95[:, (T - 1)] = pred95\n",
    "\n",
    "\n",
    "    # transformando preds em um array\n",
    "    train_size = len(X_train)\n",
    "\n",
    "    y5 = preds5.flatten()\n",
    "    y50 = preds50.flatten()\n",
    "    y95 = preds95.flatten()\n",
    "\n",
    "    x= pd.period_range(start=df_lag.index[1], end=df_lag.index[-1], freq='D').to_timestamp()\n",
    "    \n",
    "    x = np.array(x)\n",
    "    \n",
    "    y5 = np.array(y5)\n",
    "    \n",
    "    y50 = np.array(y50)\n",
    "    \n",
    "    y95 = np.array(y95)\n",
    "    \n",
    "    target = targets[1]\n",
    "    \n",
    "    train_size = len(X_train)\n",
    "    \n",
    "    dif = len(x) - len(y5)\n",
    "        \n",
    "    if dif <0:\n",
    "        y5 = y5[:len(y5) + dif]\n",
    "        y50 = y50[:len(y50) + dif]\n",
    "        y95 = y95[:len(y95) + dif]\n",
    "        \n",
    "    df_pred = pd.DataFrame()\n",
    "    df_pred['target'] = target[1:]\n",
    "    df_pred['date'] = x\n",
    "    df_pred['lower'] = y5\n",
    "    df_pred['median'] = y50\n",
    "    df_pred['upper'] = y95\n",
    "    df_pred['train_size'] = [train_size]*len(df_pred)\n",
    "    df_pred['canton'] = [target_name[-2:]]*len(df_pred)\n",
    "    \n",
    "    return df_pred\n",
    "\n",
    "def make_single_prediction(target_curve_name, canton, predictors, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    '''\n",
    "    Function to make single prediction \n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params canton: canton of interest \n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    params title: If none the title will be: Hospitalizations - canton\n",
    "    params path: If none the plot will be save in the directory: images/hosp_{canton}\n",
    "    '''\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    if updated_data: \n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "\n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df = rolling_predictions(target_name, df,  ini_date = ini_date,split = 0.75,   horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    #fig = plot_predictions(target_curve_name, canton, target, train_size, x, y5,y50, y95, forecast_dates, forecasts5, forecasts50,forecasts95, title, path)\n",
    "    return df \n",
    "\n",
    "def make_predictions_all_cantons(target_curve_name,  predictors, cluster, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None):\n",
    "\n",
    "    '''\n",
    "    Function to make prediction for all the cantons\n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params target_curve_name: string to indicate the target column of the predictions\n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    \n",
    "    returns: Dataframe with the predictions for all the cantons\n",
    "    '''\n",
    "    \n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    for canton in cluster:\n",
    "        # apply the model \n",
    "\n",
    "        target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "        horizon = 14\n",
    "        maxlag = 14\n",
    "\n",
    "        # get predictions and forecast \n",
    "            \n",
    "        df_pred = rolling_predictions(target_name, df,  ini_date = ini_date,split = 0.75,   horizon_forecast = horizon, maxlag=maxlag)\n",
    "            \n",
    "        df_all = pd.concat([df_all,df_pred])\n",
    "            \n",
    "    return df_all\n",
    "\n",
    "def rolling_forecast(target_name, data, ini_date, horizon_forecast = 14, maxlag=14):\n",
    "    \n",
    "    #print(data.index[-1])\n",
    "    data = data.iloc[:-3]\n",
    "    \n",
    "    #print(data.index[-1])\n",
    "    target = data[target_name]\n",
    "\n",
    "    df_lag = build_lagged_features(copy.deepcopy(data), maxlag=maxlag )\n",
    "\n",
    "    ini_date = max(df_lag.index[0],target.index[0], datetime.strptime(ini_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    df_lag = df_lag[ini_date:]\n",
    "    target = target[ini_date:]\n",
    "    target = target.dropna()\n",
    "    df_lag = df_lag.dropna()\n",
    "    \n",
    "    if np.sum(target) > 0.0:\n",
    "\n",
    "        # remove the target column and columns related with the day that we want to predict \n",
    "        df_lag = df_lag.drop(data.columns, axis = 1)\n",
    "\n",
    "        # targets \n",
    "        targets = {}\n",
    "\n",
    "        print(target_name)\n",
    "\n",
    "        for T in np.arange(1,horizon_forecast+1,1):\n",
    "            if T == 1:\n",
    "                targets[T] = target.shift(-(T - 1))\n",
    "            else:\n",
    "                targets[T] = target.shift(-(T - 1))[:-(T - 1)]\n",
    "    #         print(T, len(df_lag), len(fit_target))\n",
    "    #         print(df_lag.index,fit_target.index)\n",
    "\n",
    "\n",
    "        # forecast\n",
    "        forecasts5 = []\n",
    "        forecasts50 = []\n",
    "        forecasts95 = []\n",
    "\n",
    "        X_train = df_lag.iloc[:-1]\n",
    "\n",
    "\n",
    "        for T in range(1, horizon_forecast + 1):\n",
    "            # training of the model with all the data available\n",
    "\n",
    "            print(T)\n",
    "\n",
    "            tgt = targets[T][:len(X_train)]\n",
    "\n",
    "            i = 0\n",
    "\n",
    "            while i < len(tgt):\n",
    "                if tgt[i] <= 0:\n",
    "\n",
    "                    tgt[i] = 0.01\n",
    "                i = i+1\n",
    "\n",
    "\n",
    "            model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n",
    "                                 natural_gradient=True,verbose=False, col_sample = 0.9, \n",
    "                                 n_estimators=300,\n",
    "            learning_rate=0.1,\n",
    "            validation_fraction=0.25,\n",
    "            early_stopping_rounds = 50)\n",
    "\n",
    "            #print(tgt)\n",
    "\n",
    "            model.fit(X_train[:len(tgt)], tgt)\n",
    "\n",
    "            forecast = model.pred_dist(df_lag.iloc[-1:])\n",
    "\n",
    "            # make the forecast \n",
    "            forecast50 = forecast.median()\n",
    "\n",
    "            forecast5, forecast95 = forecast.interval(alpha = 0.95)\n",
    "\n",
    "\n",
    "            forecasts5.append(forecast5)\n",
    "            forecasts50.append(forecast50)\n",
    "            forecasts95.append(forecast95)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        forecasts5 = np.array([0.0]*14)\n",
    "        forecasts50 = np.array([0.0]*14)\n",
    "        forecasts95 = np.array([0.0]*14)\n",
    "\n",
    "\n",
    "    # transformando preds em um array\n",
    "\n",
    "    forecast_dates = []\n",
    "\n",
    "    last_day = datetime.strftime((df_lag.index)[-1], '%Y-%m-%d')\n",
    "\n",
    "    a = datetime.strptime(last_day, '%Y-%m-%d')\n",
    "\n",
    "    for i in np.arange(1, horizon_forecast + 1):\n",
    "\n",
    "        d_i = datetime.strftime(a+timedelta(days=int(i)),'%Y-%m-%d' ) \n",
    "\n",
    "        forecast_dates.append(datetime.strptime(d_i, '%Y-%m-%d'))\n",
    "    \n",
    "    \n",
    "    df_for = pd.DataFrame()\n",
    "\n",
    "    df_for['date'] = forecast_dates\n",
    "    df_for['lower'] = np.array(forecasts5)\n",
    "    df_for['median'] = np.array(forecasts50)\n",
    "    df_for['upper'] = np.array(forecasts95)\n",
    "    df_for['canton'] = [target_name[-2:]]*len(df_for)\n",
    "    \n",
    "    return df_for\n",
    "\n",
    "def make_forecast(target_curve_name, canton, predictors, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    if updated_data:\n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "    \n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df_for = rolling_forecast(target_name, df, ini_date = ini_date,  horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    return df_for\n",
    "\n",
    "\n",
    "def make_forecast(target_curve_name, canton, predictors, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    if updated_data:\n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "    \n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df_for = rolling_forecast(target_name, df, ini_date = ini_date,  horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    return df_for\n",
    "\n",
    "def make_forecast_all_cantons(target_curve_name, predictors, cluster, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None):\n",
    "    '''\n",
    "    Function to make the forecast for all the cantons\n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params target_curve_name: string to indicate the target column of the predictions\n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    \n",
    "    returns: Dataframe with the forecast for all the cantons\n",
    "    '''\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "        \n",
    "    for canton in cluster:\n",
    "\n",
    "        # apply the model \n",
    "\n",
    "        target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "        horizon = 14\n",
    "        maxlag = 14\n",
    "\n",
    "        # get predictions and forecast \n",
    "        df_for = rolling_forecast(target_name, df, ini_date = ini_date,  horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "        df_all= pd.concat([df_all, df_for])\n",
    "        \n",
    "    return df_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99400826",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'validation_fraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_77778/607397489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcanton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AI'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_AI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_single_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_curve_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictors2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaccine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mini_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2020-03-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_77778/3287287478.py\u001b[0m in \u001b[0;36mmake_single_prediction\u001b[0;34m(target_curve_name, canton, predictors, vaccine, smooth, ini_date, title, updated_data)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# get predictions and forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m#date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrolling_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mini_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mini_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mhorizon_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m#fig = plot_predictions(target_curve_name, canton, target, train_size, x, y5,y50, y95, forecast_dates, forecasts5, forecasts50,forecasts95, title, path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_77778/3287287478.py\u001b[0m in \u001b[0;36mrolling_predictions\u001b[0;34m(target_name, data, ini_date, split, horizon_forecast, maxlag)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n\u001b[0m\u001b[1;32m     51\u001b[0m                              \u001b[0mnatural_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                              \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'validation_fraction'"
     ]
    }
   ],
   "source": [
    "predictors1 = ['cases', 'hosp', 'test']\n",
    "predictors2 = ['cases', 'hosp', 'test', 'hospcapacity']\n",
    "\n",
    "cluster1 = ['AG', 'AR', 'BE', 'BL', 'BS', 'GL', 'LU', 'NW', 'OW', 'SG',\n",
    "        'SH', 'SO', 'SZ', 'TG', 'UR', 'ZG', 'ZH']\n",
    "cluster2 = ['FR', 'GE', 'GR', 'JU', 'NE', 'TI', 'VD', 'VS']\n",
    "\n",
    "target_curve_name = 'ICU_patients'\n",
    "canton = 'AI'\n",
    "\n",
    "df_AI = make_single_prediction(target_curve_name, canton, predictors2, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None, updated_data = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed011b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5c5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_hosp_FR\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_GE\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_GR\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_JU\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_NE\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_TI\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_VD\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "total_hosp_VS\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "CPU times: user 19min 37s, sys: 2.88 s, total: 19min 39s\n",
      "Wall time: 20min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "predictors1 = ['cases', 'hosp', 'test']\n",
    "predictors2 = ['cases', 'hosp', 'test', 'hospcapacity']\n",
    "\n",
    "cluster1 = ['AG', 'AI', 'AR', 'BE', 'BL', 'BS', 'GL', 'LU', 'NW', 'OW', 'SG',\n",
    "        'SH', 'SO', 'SZ', 'TG', 'UR', 'ZG', 'ZH']\n",
    "cluster2 = ['FR', 'GE', 'GR', 'JU', 'NE', 'TI', 'VD', 'VS']    \n",
    "df_for_total_hosp2 = make_forecast_all_cantons('total_hosp', predictors2,cluster2,  vaccine = True, smooth= True,ini_date = '2020-03-01', title = None)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca15eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_total_hosp2.to_csv('total_hosp_all_cantons2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036e9363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lower</th>\n",
       "      <th>median</th>\n",
       "      <th>upper</th>\n",
       "      <th>canton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>47.898184</td>\n",
       "      <td>48.874222</td>\n",
       "      <td>49.870149</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>45.608421</td>\n",
       "      <td>46.989676</td>\n",
       "      <td>48.412762</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>45.293087</td>\n",
       "      <td>47.157772</td>\n",
       "      <td>49.099225</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>45.393918</td>\n",
       "      <td>47.733782</td>\n",
       "      <td>50.194257</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>42.495737</td>\n",
       "      <td>45.788488</td>\n",
       "      <td>49.336375</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>62.312937</td>\n",
       "      <td>67.070053</td>\n",
       "      <td>72.190338</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>56.493264</td>\n",
       "      <td>64.712198</td>\n",
       "      <td>74.126866</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>68.764578</td>\n",
       "      <td>72.435496</td>\n",
       "      <td>76.302381</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>46.564615</td>\n",
       "      <td>51.972481</td>\n",
       "      <td>58.008399</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>55.807535</td>\n",
       "      <td>61.824213</td>\n",
       "      <td>68.489558</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      lower     median      upper canton\n",
       "0  2022-01-15  47.898184  48.874222  49.870149     FR\n",
       "1  2022-01-16  45.608421  46.989676  48.412762     FR\n",
       "2  2022-01-17  45.293087  47.157772  49.099225     FR\n",
       "3  2022-01-18  45.393918  47.733782  50.194257     FR\n",
       "4  2022-01-19  42.495737  45.788488  49.336375     FR\n",
       "..        ...        ...        ...        ...    ...\n",
       "9  2022-01-24  62.312937  67.070053  72.190338     VS\n",
       "10 2022-01-25  56.493264  64.712198  74.126866     VS\n",
       "11 2022-01-26  68.764578  72.435496  76.302381     VS\n",
       "12 2022-01-27  46.564615  51.972481  58.008399     VS\n",
       "13 2022-01-28  55.807535  61.824213  68.489558     VS\n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_total_hosp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf27b408",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_sum_dispatcher() missing 1 required positional argument: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_77778/3287287478.py\u001b[0m in \u001b[0;36mmake_forecast_all_cantons\u001b[0;34m(target_curve_name, predictors, cluster, vaccine, smooth, ini_date, title)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# get predictions and forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mdf_for\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrolling_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mini_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mini_date\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mhorizon_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mdf_all\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_for\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_77778/3287287478.py\u001b[0m in \u001b[0;36mrolling_forecast\u001b[0;34m(target_name, data, ini_date, horizon_forecast, maxlag)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mdf_lag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# remove the target column and columns related with the day that we want to predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _sum_dispatcher() missing 1 required positional argument: 'a'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictors1 = ['cases', 'hosp', 'test']\n",
    "predictors2 = ['cases', 'hosp', 'test', 'hospcapacity']\n",
    "\n",
    "cluster1 = ['AG', 'AI', 'AR', 'BE', 'BL', 'BS', 'GL', 'LU', 'NW', 'OW', 'SG',\n",
    "        'SH', 'SO', 'SZ', 'TG', 'UR', 'ZG', 'ZH']\n",
    "cluster2 = ['FR', 'GE', 'GR', 'JU', 'NE', 'TI', 'VD', 'VS']\n",
    "\n",
    "df_for_icu1 = make_forecast_all_cantons('ICU_patients', predictors2,cluster1,  vaccine = True, smooth= True,ini_date = '2020-03-01', title = None)\n",
    " \n",
    "df_for_icu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae5c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
