{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5106a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import  LogNormal\n",
    "from ngboost.scores import LogScore\n",
    "from datetime import datetime, timedelta\n",
    "from get_data import build_lagged_features, compute_clusters, get_combined_data, get_updated_data\n",
    "from sqlalchemy import create_engine\n",
    "import lightgbm as lgb\n",
    "from get_data import *\n",
    "engine = create_engine(\"postgresql://epigraph:epigraph@localhost:5432/epigraphhub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a8a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast(target_name, data, ini_date, horizon_forecast = 14, maxlag=14):\n",
    "    \n",
    "    #print(data.index[-1])\n",
    "    data = data.iloc[:-3]\n",
    "    \n",
    "    #print(data.index[-1])\n",
    "    target = data[target_name]\n",
    "\n",
    "    df_lag = build_lagged_features(copy.deepcopy(data), maxlag=maxlag )\n",
    "\n",
    "    ini_date = max(df_lag.index[0],target.index[0], datetime.strptime(ini_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    df_lag = df_lag[ini_date:]\n",
    "    target = target[ini_date:]\n",
    "    target = target.dropna()\n",
    "    df_lag = df_lag.dropna()\n",
    "\n",
    "    # remove the target column and columns related with the day that we want to predict \n",
    "    df_lag = df_lag.drop(data.columns, axis = 1)\n",
    "\n",
    "    # targets \n",
    "    targets = {}\n",
    "    \n",
    "    print(target_name)\n",
    "\n",
    "    for T in np.arange(1,horizon_forecast+1,1):\n",
    "        if T == 1:\n",
    "            targets[T] = target.shift(-(T - 1))\n",
    "        else:\n",
    "            targets[T] = target.shift(-(T - 1))[:-(T - 1)]\n",
    "#         print(T, len(df_lag), len(fit_target))\n",
    "#         print(df_lag.index,fit_target.index)\n",
    "\n",
    "\n",
    "    # forecast\n",
    "    forecasts5 = []\n",
    "    forecasts50 = []\n",
    "    forecasts95 = []\n",
    "    \n",
    "    X_train = df_lag.iloc[:-1]\n",
    "    \n",
    "\n",
    "    for T in range(1, horizon_forecast + 1):\n",
    "        # training of the model with all the data available\n",
    "        \n",
    "        print(T)\n",
    "        \n",
    "        tgt = targets[T][:len(X_train)]\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(tgt):\n",
    "            if tgt[i] <= 0:\n",
    "                \n",
    "                tgt[i] = 0.01\n",
    "            i = i+1\n",
    "            \n",
    "        \n",
    "        model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n",
    "                             natural_gradient=True,verbose=False, col_sample = 0.9, \n",
    "                             n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        validation_fraction=0.25,\n",
    "        early_stopping_rounds = 50)\n",
    "        \n",
    "        #print(tgt)\n",
    "        \n",
    "        for i in tgt:\n",
    "            print(i)\n",
    "\n",
    "        model.fit(X_train[:len(tgt)], tgt)\n",
    "        \n",
    "        forecast = model.pred_dist(df_lag.iloc[-1:])\n",
    "\n",
    "        # make the forecast \n",
    "        forecast50 = forecast.median()\n",
    "        \n",
    "        forecast5, forecast95 = forecast.interval(alpha = 0.95)\n",
    "        \n",
    "        \n",
    "        forecasts5.append(forecast5)\n",
    "        forecasts50.append(forecast50)\n",
    "        forecasts95.append(forecast95)\n",
    "\n",
    "\n",
    "    # transformando preds em um array\n",
    "\n",
    "    forecast_dates = []\n",
    "\n",
    "    last_day = datetime.strftime((df_lag.index)[-1], '%Y-%m-%d')\n",
    "\n",
    "    a = datetime.strptime(last_day, '%Y-%m-%d')\n",
    "\n",
    "    for i in np.arange(1, horizon_forecast + 1):\n",
    "\n",
    "        d_i = datetime.strftime(a+timedelta(days=int(i)),'%Y-%m-%d' ) \n",
    "\n",
    "        forecast_dates.append(datetime.strptime(d_i, '%Y-%m-%d'))\n",
    "    \n",
    "    \n",
    "    df_for = pd.DataFrame()\n",
    "\n",
    "    df_for['date'] = forecast_dates\n",
    "    df_for['lower'] = np.array(forecasts5)[:,0]\n",
    "    df_for['median'] = np.array(forecasts50)[:,0]\n",
    "    df_for['upper'] = np.array(forecasts95)[:,0]\n",
    "    df_for['canton'] = [target_name[-2:]]*len(df_for)\n",
    "    \n",
    "    return df_for\n",
    "\n",
    "def make_forecast(target_curve_name, canton, predictors, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    if updated_data:\n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "    \n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df_for = rolling_forecast(target_name, df, ini_date = ini_date,  horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    return df_for\n",
    "\n",
    "\n",
    "def make_forecast(target_curve_name, canton, predictors, vaccine = True, smooth= True, ini_date = '2020-03-01', title = None, updated_data = True):\n",
    "\n",
    "    # compute the clusters \n",
    "    clusters, all_regions,fig = compute_clusters('cases', t=0.8, plot = False)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        if canton in cluster:\n",
    "\n",
    "            cluster_canton = cluster\n",
    "\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster_canton, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    if updated_data:\n",
    "        # atualizando a coluna das Hospitalizações com os dados mais atualizados\n",
    "        df_new = get_updated_data(smooth)\n",
    "    \n",
    "        df.loc[df_new.index[0]: df_new.index[-1], 'hosp_GE'] = df_new.hosp_GE\n",
    "    \n",
    "        # utilizando como último data a data dos dados atualizados:\n",
    "        df = df.loc[:df_new.index[-1]]\n",
    "\n",
    "\n",
    "    # apply the model \n",
    "\n",
    "    target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "    horizon = 14\n",
    "    maxlag = 14\n",
    "\n",
    "    # get predictions and forecast \n",
    "    #date_predsknn, predsknn, targetknn, train_size, date_forecastknn, forecastknn = rolling_predictions(model_knn, 'knn', target_name, df , ini_date = '2021-01-01',split = 0.75,   horizon_forecast = horizon, maxlag=maxlag,)\n",
    "    df_for = rolling_forecast(target_name, df, ini_date = ini_date,  horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "    return df_for\n",
    "\n",
    "def make_forecast_all_cantons(target_curve_name, predictors, cluster, vaccine = True, smooth= True,ini_date = '2020-03-01', title = None):\n",
    "    '''\n",
    "    Function to make the forecast for all the cantons\n",
    "    \n",
    "    Important: \n",
    "    * By default the function is using the clustering cantons and the data since 2020\n",
    "    * For the predictor hospCapacity is used as predictor the column ICU_Covid19Patients\n",
    "    \n",
    "    params target_curve_name: string to indicate the target column of the predictions\n",
    "    params predictors: variables that  will be used in model \n",
    "    params vaccine: It determines if the vaccine data from owid will be used or not \n",
    "    params smooth: It determines if data will be smoothed or not \n",
    "    params ini_date: Determines the beggining of the train dataset\n",
    "    \n",
    "    returns: Dataframe with the forecast for all the cantons\n",
    "    '''\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    # getting the data \n",
    "    df = get_combined_data(predictors, cluster, vaccine=vaccine, smooth = smooth)\n",
    "    # filling the nan values with 0\n",
    "    df = df.fillna(0)\n",
    "        \n",
    "    for canton in cluster:\n",
    "\n",
    "        # apply the model \n",
    "\n",
    "        target_name = f'{target_curve_name}_{canton}'\n",
    "\n",
    "        horizon = 14\n",
    "        maxlag = 14\n",
    "\n",
    "        # get predictions and forecast \n",
    "        df_for = rolling_forecast(target_name, df, ini_date = ini_date,  horizon_forecast = horizon, maxlag=maxlag)\n",
    "\n",
    "        df_all= pd.concat([df_all, df_for])\n",
    "        \n",
    "    return df_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f049271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases_AI</th>\n",
       "      <th>diff_cases_AI</th>\n",
       "      <th>diff_2_cases_AI</th>\n",
       "      <th>hosp_AI</th>\n",
       "      <th>diff_hosp_AI</th>\n",
       "      <th>diff_2_hosp_AI</th>\n",
       "      <th>test_AI</th>\n",
       "      <th>diff_test_AI</th>\n",
       "      <th>diff_2_test_AI</th>\n",
       "      <th>ICU_patients_AI</th>\n",
       "      <th>total_hosp_AI</th>\n",
       "      <th>vac_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>35.714286</td>\n",
       "      <td>-2.428571</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>-8.285714</td>\n",
       "      <td>-9.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>36.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.857143</td>\n",
       "      <td>-4.857143</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-15</th>\n",
       "      <td>38.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>85.285714</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.152857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-16</th>\n",
       "      <td>37.857143</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-2.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>85.142857</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-4.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-17</th>\n",
       "      <td>30.142857</td>\n",
       "      <td>-7.714286</td>\n",
       "      <td>-7.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.285714</td>\n",
       "      <td>-5.857143</td>\n",
       "      <td>-5.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.451429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>653 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cases_AI  diff_cases_AI  diff_2_cases_AI   hosp_AI  diff_hosp_AI  \\\n",
       "2020-04-05   1.000000       0.000000         0.142857  0.000000      0.000000   \n",
       "2020-04-06   1.000000       0.000000         0.000000  0.000000      0.000000   \n",
       "2020-04-07   0.857143      -0.142857        -0.142857  0.000000      0.000000   \n",
       "2020-04-08   0.571429      -0.285714        -0.142857  0.000000      0.000000   \n",
       "2020-04-09   0.571429       0.000000         0.285714  0.000000      0.000000   \n",
       "...               ...            ...              ...       ...           ...   \n",
       "2022-01-13  35.714286      -2.428571        -2.000000  0.142857      0.000000   \n",
       "2022-01-14  36.142857       0.428571         2.857143  0.142857      0.000000   \n",
       "2022-01-15  38.285714       2.142857         1.714286  0.000000     -0.142857   \n",
       "2022-01-16  37.857143      -0.428571        -2.571429  0.000000      0.000000   \n",
       "2022-01-17  30.142857      -7.714286        -7.285714  0.000000      0.000000   \n",
       "\n",
       "            diff_2_hosp_AI    test_AI  diff_test_AI  diff_2_test_AI  \\\n",
       "2020-04-05        0.000000   0.000000      0.000000        0.000000   \n",
       "2020-04-06        0.000000   0.000000      0.000000        0.000000   \n",
       "2020-04-07        0.000000   0.000000      0.000000        0.000000   \n",
       "2020-04-08        0.000000   0.000000      0.000000        0.000000   \n",
       "2020-04-09        0.000000   0.000000      0.000000        0.000000   \n",
       "...                    ...        ...           ...             ...   \n",
       "2022-01-13        0.000000  85.714286     -8.285714       -9.285714   \n",
       "2022-01-14        0.000000  80.857143     -4.857143        3.428571   \n",
       "2022-01-15       -0.142857  85.285714      4.428571        9.285714   \n",
       "2022-01-16        0.142857  85.142857     -0.142857       -4.571429   \n",
       "2022-01-17        0.000000  79.285714     -5.857143       -5.714286   \n",
       "\n",
       "            ICU_patients_AI  total_hosp_AI     vac_all  \n",
       "2020-04-05              0.0            0.0    0.000000  \n",
       "2020-04-06              0.0            0.0    0.000000  \n",
       "2020-04-07              0.0            0.0    0.000000  \n",
       "2020-04-08              0.0            0.0    0.000000  \n",
       "2020-04-09              0.0            0.0    0.000000  \n",
       "...                     ...            ...         ...  \n",
       "2022-01-13              0.0            0.0  165.690000  \n",
       "2022-01-14              0.0            0.0  166.428571  \n",
       "2022-01-15              0.0            0.0  167.152857  \n",
       "2022-01-16              0.0            0.0  167.860000  \n",
       "2022-01-17              0.0            0.0  168.451429  \n",
       "\n",
       "[653 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors2 = ['cases', 'hosp', 'test', 'hospcapacity']\n",
    "\n",
    "cluster1 = ['AI']\n",
    "\n",
    "df = get_combined_data(predictors2, cluster1, vaccine= True, smooth = True)\n",
    "    # filling the nan values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4ccd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'ICU_patients_AI'\n",
    "horizon_forecast = 14\n",
    "maxlag = 14\n",
    "ini_date = '2020-03-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684d17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum target: 0.0\n"
     ]
    }
   ],
   "source": [
    "#print(data.index[-1])\n",
    "\n",
    "data  = df \n",
    "data = data.iloc[:-3]\n",
    "    \n",
    "#print(data.index[-1])\n",
    "target = data[target_name]\n",
    "\n",
    "print('Sum target:', np.sum(target))\n",
    "\n",
    "df_lag = build_lagged_features(copy.deepcopy(data), maxlag=maxlag )\n",
    "\n",
    "ini_date = max(df_lag.index[0],target.index[0], datetime.strptime(ini_date, \"%Y-%m-%d\"))\n",
    "\n",
    "df_lag = df_lag[ini_date:]\n",
    "target = target[ini_date:]\n",
    "df_lag = df_lag.dropna()\n",
    "\n",
    "df_lag = df_lag.drop(data.columns, axis = 1)\n",
    "\n",
    "\n",
    "targets = {}\n",
    "\n",
    "for T in np.arange(1,horizon_forecast+1,1):\n",
    "        if T == 1:\n",
    "            targets[T] = target.shift(-(T - 1))\n",
    "        else:\n",
    "            targets[T] = target.shift(-(T - 1))[:-(T - 1)]\n",
    "            \n",
    "X_train = df_lag.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b718a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = targets[1][:len(X_train)]\n",
    "\n",
    "i = 0\n",
    "while i < len(tgt):\n",
    "    if tgt[i] <= 0:\n",
    "                \n",
    "        tgt[i] = 0.01\n",
    "    i = i+1\n",
    "\n",
    "#tgt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31512bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nan values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of Nan values:')\n",
    "sum(np.isnan(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8019e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of no finite values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of no finite values:')\n",
    "sum(~np.isfinite(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a05ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_92277/2311024756.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  model.fit(X_train.iloc[:len(tgt)].values, np.nan_to_num(tgt.astype(np.float)))\n",
      "/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/distns/lognormal.py:125: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.array([m, np.log(s)])\n",
      "/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/distns/lognormal.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z = (lT - self.loc) / self.scale\n",
      "/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/distns/lognormal.py:25: RuntimeWarning: invalid value encountered in true_divide\n",
      "  D_uncens[:, 0] = (self.loc - lT) / (self.scale ** 2)\n",
      "/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/distns/lognormal.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "  D_uncens[:, 1] = 1 - ((self.loc - lT) ** 2) / (self.scale ** 2)\n",
      "/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py:1870: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mw/sfchnv0s53v80k_qgy_21qfh0000gn/T/ipykernel_92277/2311024756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         learning_rate=0.01)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/ngboost.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnatural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mproj_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/ngboost.py\u001b[0m in \u001b[0;36mfit_base\u001b[0;34m(self, X, grads, sample_weight)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         models = [\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         ]\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/ngboost/ngboost.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         models = [\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         ]\n\u001b[1;32m    168\u001b[0m         \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             )\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/swiss_covid19/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "model = NGBRegressor(Base=default_tree_learner, Dist =LogNormal,Score = LogScore,\n",
    "                             natural_gradient=False,verbose=False, col_sample = 0.9, \n",
    "                             n_estimators=100,\n",
    "        learning_rate=0.01)\n",
    "            \n",
    "model.fit(X_train.iloc[:len(tgt)].values, np.nan_to_num(tgt.astype(np.float)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
