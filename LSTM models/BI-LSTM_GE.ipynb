{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013c6e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T17:49:32.933092Z",
     "iopub.status.busy": "2022-01-21T17:49:32.932887Z",
     "iopub.status.idle": "2022-01-21T17:49:35.500614Z",
     "shell.execute_reply": "2022-01-21T17:49:35.500115Z",
     "shell.execute_reply.started": "2022-01-21T17:49:32.933066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as P\n",
    "import tensorflow.keras as  keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import shap\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from time import time\n",
    "#from get_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6188a90a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T17:49:35.502301Z",
     "iopub.status.busy": "2022-01-21T17:49:35.502036Z",
     "iopub.status.idle": "2022-01-21T17:49:35.509258Z",
     "shell.execute_reply": "2022-01-21T17:49:35.508691Z",
     "shell.execute_reply.started": "2022-01-21T17:49:35.502278Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(df, look_back=12, ratio=0.8, predict_n=5, Y_column=0):\n",
    "    \"\"\"\n",
    "    Split the data into training and test sets\n",
    "    Keras expects the input tensor to have a shape of (nb_samples, timesteps, features).\n",
    "    :param df: Pandas dataframe with the data.\n",
    "    :param look_back: Number of weeks to look back before predicting\n",
    "    :param ratio: fraction of total samples to use for training\n",
    "    :param predict_n: number of weeks to predict\n",
    "    :param Y_column: Column to predict\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df = np.nan_to_num(df.values).astype(\"float64\")\n",
    "    # n_ts is the number of training samples also number of training sets\n",
    "    # since windows have an overlap of n-1\n",
    "    n_ts = df.shape[0] - look_back - predict_n + 1\n",
    "    # data = np.empty((n_ts, look_back + predict_n, df.shape[1]))\n",
    "    data = np.empty((n_ts, look_back + predict_n, df.shape[1]))\n",
    "    for i in range(n_ts):  # - predict_):\n",
    "        #         print(i, df[i: look_back+i+predict_n,0])\n",
    "        data[i, :, :] = df[i: look_back + i + predict_n, :]\n",
    "    # train_size = int(n_ts * ratio)\n",
    "    train_size = int(df.shape[0] * ratio) - look_back\n",
    "    print(train_size)\n",
    "\n",
    "    # We are predicting only column 0\n",
    "    X_train = data[:train_size, :look_back, :]\n",
    "    Y_train = data[:train_size, look_back:, Y_column]\n",
    "    X_test = data[train_size:, :look_back, :]\n",
    "    Y_test = data[train_size:, look_back:, Y_column]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def normalize_data(df, log_transform=False):\n",
    "    \"\"\"\n",
    "    Normalize features in the example table\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"     \n",
    "    df.fillna(0, inplace=True)\n",
    "    norm = normalize(df, norm='max', axis=0)\n",
    "    if log_transform==True:\n",
    "        norm = np.log(norm)\n",
    "    df_norm = pd.DataFrame(norm, columns=df.columns)\n",
    "\n",
    "    return df_norm, df.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456a7e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T17:49:35.510504Z",
     "iopub.status.busy": "2022-01-21T17:49:35.510312Z",
     "iopub.status.idle": "2022-01-21T17:49:35.535956Z",
     "shell.execute_reply": "2022-01-21T17:49:35.535397Z",
     "shell.execute_reply.started": "2022-01-21T17:49:35.510486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(hidden, features, predict_n, look_back=10, batch_size=1):\n",
    "    \"\"\"\n",
    "    Builds and returns the LSTM model with the parameters given\n",
    "    :param hidden: number of hidden nodes\n",
    "    :param features: number of variables in the example table\n",
    "    :param look_back: Number of time-steps to look back before predicting\n",
    "    :param batch_size: batch size for batch training\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    inp = keras.Input(\n",
    "        shape=(look_back, features),\n",
    "        # batch_shape=(batch_size, look_back, features)\n",
    "    )\n",
    "    x = Bidirectional(LSTM(\n",
    "        hidden,\n",
    "        input_shape=(look_back, features),\n",
    "        stateful=False,\n",
    "        batch_input_shape=(batch_size, look_back, features),\n",
    "        return_sequences=True,\n",
    "         activation='relu',\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.1,\n",
    "        implementation=2,\n",
    "        unit_forget_bias=True,\n",
    "    ), merge_mode = 'ave')(inp, training=True)\n",
    "    x = Dropout(0.2)(x, training=True)\n",
    "    x = Bidirectional(LSTM(\n",
    "        hidden,\n",
    "        input_shape=(look_back, features),\n",
    "        stateful=False,\n",
    "        batch_input_shape=(batch_size, look_back, features),\n",
    "        #return_sequences=True,\n",
    "         activation='relu',\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.1,\n",
    "        implementation=2,\n",
    "        unit_forget_bias=True,\n",
    "    ), merge_mode = 'ave')(inp, training=True)\n",
    "    x = Dropout(0.2)(x, training=True)\n",
    "    out = Dense(\n",
    "        predict_n,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"random_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "    )(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    start = time()\n",
    "    model.compile(loss=\"msle\", optimizer=\"adam\", metrics=[\"accuracy\", \"mape\", \"mse\"])\n",
    "    print(\"Compilation Time : \", time() - start)\n",
    "    plot_model(model, to_file=\"LSTM_model.png\")\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, X_train, Y_train, batch_size=1, epochs=10, geocode=None, overwrite=True):\n",
    "    TB_callback = TensorBoard(\n",
    "        log_dir=\"./tensorboard\",\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        # embeddings_freq=10\n",
    "    )\n",
    "\n",
    "    hist = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.15,\n",
    "        verbose=1,\n",
    "        callbacks=[TB_callback, EarlyStopping(patience=15)]\n",
    "    )\n",
    "    with open(\"history_{}.pkl\".format(geocode), \"wb\") as f:\n",
    "        pickle.dump(hist.history, f)\n",
    "    model.save_weights(\"trained_{}_model.h5\".format(geocode), overwrite=overwrite)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def plot_training_history(hist):\n",
    "    \"\"\"\n",
    "    Plot the Loss series from training the model\n",
    "    :param hist: Training history object returned by \"model.fit()\"\n",
    "    \"\"\"\n",
    "    df_vloss = pd.DataFrame(hist.history[\"val_loss\"], columns=[\"val_loss\"])\n",
    "    df_loss = pd.DataFrame(hist.history[\"loss\"], columns=[\"loss\"])\n",
    "    df_mape = pd.DataFrame(\n",
    "        hist.history[\"mean_absolute_percentage_error\"], columns=[\"mape\"]\n",
    "    )\n",
    "    ax = df_vloss.plot(logy=True)\n",
    "    df_loss.plot(ax=ax, grid=True, logy=True)\n",
    "    # df_mape.plot(ax=ax, grid=True, logy=True);\n",
    "    # P.savefig(\"{}/LSTM_training_history.png\".format(FIG_PATH))\n",
    "\n",
    "\n",
    "def plot_predicted_vs_data(predicted, Ydata, indice, label, pred_window, factor, split_point=None, uncertainty=False):\n",
    "    \"\"\"\n",
    "    Plot the model's predictions against data\n",
    "    :param predicted: model predictions\n",
    "    :param Ydata: observed data\n",
    "    :param indice:\n",
    "    :param label: Name of the locality of the predictions\n",
    "    :param pred_window:\n",
    "    :param factor: Normalizing factor for the target variable\n",
    "    \"\"\"\n",
    "\n",
    "    P.clf()\n",
    "    if len(predicted.shape) == 2:\n",
    "        df_predicted = pd.DataFrame(predicted)\n",
    "        df_predicted25 = None\n",
    "    else:\n",
    "        df_predicted = pd.DataFrame(np.percentile(predicted, 50, axis=2))\n",
    "        df_predicted25 = pd.DataFrame(np.percentile(predicted, 2.5, axis=2))\n",
    "        df_predicted975 = pd.DataFrame(np.percentile(predicted, 97.5, axis=2))\n",
    "        uncertainty = True\n",
    "    ymax = max(predicted.max() * factor, Ydata.max() * factor)\n",
    "    P.vlines(indice[split_point], 0, ymax, \"g\", \"dashdot\", lw=2)\n",
    "    P.text(indice[split_point + 2], 0.6 * ymax, \"Out of sample Predictions\")\n",
    "    # plot only the last (furthest) prediction point\n",
    "    P.plot(indice[len(indice)-Ydata.shape[0]:], Ydata[:, -1] * factor, 'k-', alpha=0.7, label='data')\n",
    "    P.plot(indice[len(indice)-Ydata.shape[0]:], df_predicted.iloc[:,-1] * factor, 'r-', alpha=0.5, label='median')\n",
    "    if uncertainty:\n",
    "        P.fill_between(indice[len(indice)-Ydata.shape[0]:], df_predicted25[df_predicted25.columns[-1]] * factor,\n",
    "                       df_predicted975[df_predicted975.columns[-1]] * factor,\n",
    "                       color='b', alpha=0.3)\n",
    "\n",
    "    # plot all predicted points\n",
    "    # P.plot(indice[pred_window:], pd.DataFrame(Ydata)[7] * factor, 'k-')\n",
    "    # for n in range(df_predicted.shape[1] - pred_window):\n",
    "    #     P.plot(\n",
    "    #         indice[n: n + pred_window],\n",
    "    #         pd.DataFrame(Ydata.T)[n] * factor,\n",
    "    #         \"k-\",\n",
    "    #         alpha=0.7,\n",
    "    #     )\n",
    "    #     P.plot(indice[n: n + pred_window], df_predicted[n] * factor, \"r-\")\n",
    "    #     try:\n",
    "    #         P.vlines(\n",
    "    #             indice[n + pred_window],\n",
    "    #             0,\n",
    "    #             df_predicted[n].values[-1] * factor,\n",
    "    #             \"b\",\n",
    "    #             alpha=0.2,\n",
    "    #         )\n",
    "    #     except IndexError as e:\n",
    "    #         print(indice.shape, n, df_predicted.shape)\n",
    "    tag = '_unc' if uncertainty else ''\n",
    "    P.grid()\n",
    "    P.title(\"Predictions for {}\".format(label))\n",
    "    P.xlabel(\"time\")\n",
    "    P.ylabel(\"incidence\")\n",
    "    P.xticks(rotation=70)\n",
    "    P.legend([\"data\", \"predicted\"])\n",
    "    P.savefig(\n",
    "        \"lstm_{}{}.png\".format(label, tag),\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "    P.show()\n",
    "\n",
    "\n",
    "def loss_and_metrics(model, Xtest, Ytest):\n",
    "    print(model.evaluate(Xtest, Ytest, batch_size=1))\n",
    "\n",
    "\n",
    "def evaluate(model, Xdata, Ydata, label, uncertainty=False):\n",
    "    loss_and_metrics(model, Xdata, Ydata)\n",
    "    metrics = model.evaluate(Xdata, Ydata, batch_size=1)\n",
    "    # with open('metrics_{}.pkl'.format(label), 'wb') as f:\n",
    "    #     pickle.dump(metrics, f)\n",
    "    if uncertainty:\n",
    "        predicted = np.stack([model.predict(Xdata, batch_size=1, verbose=1) for i in range(100)], axis=2)\n",
    "    else:\n",
    "        predicted = model.predict(Xdata, batch_size=1, verbose=1)\n",
    "    return predicted, metrics\n",
    "\n",
    "\n",
    "def calculate_metrics(pred, ytrue, factor):\n",
    "    metrics = pd.DataFrame(\n",
    "        index=(\n",
    "            \"mean_absolute_error\",\n",
    "            \"explained_variance_score\",\n",
    "            \"mean_squared_error\",\n",
    "            \"mean_squared_log_error\",\n",
    "            \"median_absolute_error\",\n",
    "            \"r2_score\",\n",
    "        )\n",
    "    )\n",
    "    for col in range(pred.shape[1]):\n",
    "        y = ytrue[:, col] * factor\n",
    "        p = pred[:, col] * factor\n",
    "        l = [\n",
    "            mean_absolute_error(y, p),\n",
    "            explained_variance_score(y, p),\n",
    "            mean_squared_error(y, p),\n",
    "            mean_squared_log_error(y, p),\n",
    "            median_absolute_error(y, p),\n",
    "            r2_score(y, p),\n",
    "        ]\n",
    "        metrics[col] = l\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_evaluate_model(target_name, data, predict_n, look_back, hidden, epochs, ratio=0.75, cluster=True, load=False,\n",
    "                         uncertainty=True):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    :param city: Name of the city\n",
    "    :param data: Dataset\n",
    "    :param predict_n: Number of steps ahead to be predicted\n",
    "    :param look_back: number of history steps to include in training window\n",
    "    :param hidden: Number of Hidden layer\n",
    "    :param epochs: number of training epochs\n",
    "    :param ratio: ratio of the full dataset to use in training\n",
    "    :param load: Whether to load a previously saved model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "        \n",
    "    target_col = data.columns.get_loc(\"hosp_GE\")\n",
    "   \n",
    "    norm_data, max_features = normalize_data(data)\n",
    "    \n",
    "    factor = max_features[target_col]\n",
    "\n",
    "    ##split test and train\n",
    "    X_train, Y_train, X_test, Y_test = split_data(\n",
    "        norm_data,\n",
    "        look_back=look_back,\n",
    "        ratio=ratio,\n",
    "        predict_n=predict_n,\n",
    "        Y_column=target_col,\n",
    "    )\n",
    "    # print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "\n",
    "    ## Run model\n",
    "    model = build_model(\n",
    "        hidden, X_train.shape[2], predict_n=predict_n, look_back=look_back\n",
    "    )\n",
    "    #if load:\n",
    "        #model.load_model(\"../saved_models/LSTM/{}/lstm_{}_epochs_{}.h5\".format(STATE, city, epochs))\n",
    "        \n",
    "    history = train(model, X_train, Y_train, batch_size=1, epochs=epochs, geocode=target_name)\n",
    "    model.save('lstm_{}_epochs_{}.h5'.format(target_name, epochs))\n",
    "\n",
    "    predicted_out, metrics_out = evaluate(model, X_test, Y_test, label=\"out_of_sample_{}\".format(target_name), uncertainty=uncertainty\n",
    "    )\n",
    "    predicted_in, metrics_in = evaluate(model, X_train, Y_train, label=\"in_sample_{}\".format(target_name), uncertainty=uncertainty\n",
    "    )\n",
    "    if uncertainty:\n",
    "        pout = np.percentile(predicted_out, 50, axis=2)\n",
    "    else:\n",
    "        pout = predicted_out\n",
    "    if ratio < 1:\n",
    "        metrics = calculate_metrics(pout, Y_test, factor)\n",
    "        metrics.to_pickle(\n",
    "            \"metrics_lstm_{}_8pw.pkl\".format(target_name)\n",
    "        )\n",
    "\n",
    "    if ratio < 1:\n",
    "        predicted = np.concatenate((predicted_in, predicted_out), axis=0)\n",
    "    else:  # In this case there is no Test set (ratio=1)\n",
    "        predicted = predicted_in\n",
    "    with open(\n",
    "            \"predicted_lstm_{}_8pw.pkl\".format(target_name), \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(predicted, f)\n",
    "\n",
    "    return predicted, X_train, X_test, Y_test, Y_train, factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660533de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T17:49:35.537335Z",
     "iopub.status.busy": "2022-01-21T17:49:35.536970Z",
     "iopub.status.idle": "2022-01-21T17:49:35.580454Z",
     "shell.execute_reply": "2022-01-21T17:49:35.579880Z",
     "shell.execute_reply.started": "2022-01-21T17:49:35.537312Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases_FR</th>\n",
       "      <th>diff_cases_FR</th>\n",
       "      <th>diff_2_cases_FR</th>\n",
       "      <th>cases_GE</th>\n",
       "      <th>diff_cases_GE</th>\n",
       "      <th>diff_2_cases_GE</th>\n",
       "      <th>cases_GR</th>\n",
       "      <th>diff_cases_GR</th>\n",
       "      <th>diff_2_cases_GR</th>\n",
       "      <th>cases_JU</th>\n",
       "      <th>...</th>\n",
       "      <th>test_TI</th>\n",
       "      <th>diff_test_TI</th>\n",
       "      <th>diff_2_test_TI</th>\n",
       "      <th>test_VD</th>\n",
       "      <th>diff_test_VD</th>\n",
       "      <th>diff_2_test_VD</th>\n",
       "      <th>test_VS</th>\n",
       "      <th>diff_test_VS</th>\n",
       "      <th>diff_2_test_VS</th>\n",
       "      <th>vac_all</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>68.285714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>130.571429</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>72.857143</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1114.428571</td>\n",
       "      <td>-15.285714</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>2115.714286</td>\n",
       "      <td>-32.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>834.571429</td>\n",
       "      <td>20.142857</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>0.044286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>134.714286</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>75.285714</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1124.857143</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>25.714286</td>\n",
       "      <td>2085.714286</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>864.285714</td>\n",
       "      <td>29.714286</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.052857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>134.142857</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-4.714286</td>\n",
       "      <td>75.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.428571</td>\n",
       "      <td>32.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>1133.428571</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>-1.857143</td>\n",
       "      <td>2097.142857</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>41.428571</td>\n",
       "      <td>882.142857</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>-11.857143</td>\n",
       "      <td>0.061429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>127.857143</td>\n",
       "      <td>-6.285714</td>\n",
       "      <td>-5.714286</td>\n",
       "      <td>75.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>36.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1179.428571</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>37.428571</td>\n",
       "      <td>2152.285714</td>\n",
       "      <td>55.142857</td>\n",
       "      <td>43.714286</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.074286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>124.857143</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>75.428571</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>37.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1194.428571</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>2173.285714</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-34.142857</td>\n",
       "      <td>918.714286</td>\n",
       "      <td>33.714286</td>\n",
       "      <td>30.857143</td>\n",
       "      <td>0.095714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09</th>\n",
       "      <td>1352.000000</td>\n",
       "      <td>-4.571429</td>\n",
       "      <td>-70.428571</td>\n",
       "      <td>2443.428571</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-119.857143</td>\n",
       "      <td>1013.285714</td>\n",
       "      <td>-13.714286</td>\n",
       "      <td>-48.571429</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3794.285714</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>-192.714286</td>\n",
       "      <td>8843.142857</td>\n",
       "      <td>111.857143</td>\n",
       "      <td>-507.428571</td>\n",
       "      <td>4036.571429</td>\n",
       "      <td>53.571429</td>\n",
       "      <td>-170.285714</td>\n",
       "      <td>162.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>1363.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>2520.571429</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>78.285714</td>\n",
       "      <td>975.285714</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-24.285714</td>\n",
       "      <td>348.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>3848.000000</td>\n",
       "      <td>53.714286</td>\n",
       "      <td>-7.285714</td>\n",
       "      <td>9018.714286</td>\n",
       "      <td>175.571429</td>\n",
       "      <td>63.714286</td>\n",
       "      <td>4030.142857</td>\n",
       "      <td>-6.428571</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>163.337143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>1334.857143</td>\n",
       "      <td>-28.142857</td>\n",
       "      <td>-39.142857</td>\n",
       "      <td>2515.857143</td>\n",
       "      <td>-4.714286</td>\n",
       "      <td>-81.857143</td>\n",
       "      <td>927.857143</td>\n",
       "      <td>-47.428571</td>\n",
       "      <td>-9.428571</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3851.714286</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>9028.142857</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>-166.142857</td>\n",
       "      <td>3984.571429</td>\n",
       "      <td>-45.571429</td>\n",
       "      <td>-39.142857</td>\n",
       "      <td>164.125714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>1288.857143</td>\n",
       "      <td>-46.000000</td>\n",
       "      <td>-17.857143</td>\n",
       "      <td>2475.142857</td>\n",
       "      <td>-40.714286</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>843.571429</td>\n",
       "      <td>-84.285714</td>\n",
       "      <td>-36.857143</td>\n",
       "      <td>293.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>3727.142857</td>\n",
       "      <td>-124.571429</td>\n",
       "      <td>-128.285714</td>\n",
       "      <td>8877.000000</td>\n",
       "      <td>-151.142857</td>\n",
       "      <td>-160.571429</td>\n",
       "      <td>3904.571429</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-34.428571</td>\n",
       "      <td>164.895714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>1198.714286</td>\n",
       "      <td>-90.142857</td>\n",
       "      <td>-44.142857</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>-145.142857</td>\n",
       "      <td>-104.428571</td>\n",
       "      <td>759.428571</td>\n",
       "      <td>-84.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>251.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>3733.714286</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>131.142857</td>\n",
       "      <td>8490.428571</td>\n",
       "      <td>-386.571429</td>\n",
       "      <td>-235.428571</td>\n",
       "      <td>3753.428571</td>\n",
       "      <td>-151.142857</td>\n",
       "      <td>-71.142857</td>\n",
       "      <td>165.647143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cases_FR  diff_cases_FR  diff_2_cases_FR     cases_GE  \\\n",
       "datum                                                                  \n",
       "2021-01-01    68.285714       0.571429        -1.142857   130.571429   \n",
       "2021-01-02    72.000000       3.714286         3.142857   134.714286   \n",
       "2021-01-03    75.000000       3.000000        -0.714286   134.142857   \n",
       "2021-01-04    83.000000       8.000000         5.000000   127.857143   \n",
       "2021-01-05    89.000000       6.000000        -2.000000   124.857143   \n",
       "...                 ...            ...              ...          ...   \n",
       "2022-01-09  1352.000000      -4.571429       -70.428571  2443.428571   \n",
       "2022-01-10  1363.000000      11.000000        15.571429  2520.571429   \n",
       "2022-01-11  1334.857143     -28.142857       -39.142857  2515.857143   \n",
       "2022-01-12  1288.857143     -46.000000       -17.857143  2475.142857   \n",
       "2022-01-13  1198.714286     -90.142857       -44.142857  2330.000000   \n",
       "\n",
       "            diff_cases_GE  diff_2_cases_GE     cases_GR  diff_cases_GR  \\\n",
       "datum                                                                    \n",
       "2021-01-01       2.285714         3.714286    72.857143      -0.285714   \n",
       "2021-01-02       4.142857         1.857143    75.285714       2.428571   \n",
       "2021-01-03      -0.571429        -4.714286    75.285714       0.000000   \n",
       "2021-01-04      -6.285714        -5.714286    75.571429       0.285714   \n",
       "2021-01-05      -3.000000         3.285714    75.428571      -0.142857   \n",
       "...                   ...              ...          ...            ...   \n",
       "2022-01-09      -1.142857      -119.857143  1013.285714     -13.714286   \n",
       "2022-01-10      77.142857        78.285714   975.285714     -38.000000   \n",
       "2022-01-11      -4.714286       -81.857143   927.857143     -47.428571   \n",
       "2022-01-12     -40.714286       -36.000000   843.571429     -84.285714   \n",
       "2022-01-13    -145.142857      -104.428571   759.428571     -84.142857   \n",
       "\n",
       "            diff_2_cases_GR    cases_JU  ...      test_TI  diff_test_TI  \\\n",
       "datum                                    ...                              \n",
       "2021-01-01        -3.000000   29.000000  ...  1114.428571    -15.285714   \n",
       "2021-01-02         2.714286   30.000000  ...  1124.857143     10.428571   \n",
       "2021-01-03        -2.428571   32.285714  ...  1133.428571      8.571429   \n",
       "2021-01-04         0.285714   36.142857  ...  1179.428571     46.000000   \n",
       "2021-01-05        -0.428571   37.142857  ...  1194.428571     15.000000   \n",
       "...                     ...         ...  ...          ...           ...   \n",
       "2022-01-09       -48.571429  382.000000  ...  3794.285714     61.000000   \n",
       "2022-01-10       -24.285714  348.571429  ...  3848.000000     53.714286   \n",
       "2022-01-11        -9.428571  319.000000  ...  3851.714286      3.714286   \n",
       "2022-01-12       -36.857143  293.571429  ...  3727.142857   -124.571429   \n",
       "2022-01-13         0.142857  251.571429  ...  3733.714286      6.571429   \n",
       "\n",
       "            diff_2_test_TI      test_VD  diff_test_VD  diff_2_test_VD  \\\n",
       "datum                                                                   \n",
       "2021-01-01       10.571429  2115.714286    -32.000000      129.000000   \n",
       "2021-01-02       25.714286  2085.714286    -30.000000        2.000000   \n",
       "2021-01-03       -1.857143  2097.142857     11.428571       41.428571   \n",
       "2021-01-04       37.428571  2152.285714     55.142857       43.714286   \n",
       "2021-01-05      -31.000000  2173.285714     21.000000      -34.142857   \n",
       "...                    ...          ...           ...             ...   \n",
       "2022-01-09     -192.714286  8843.142857    111.857143     -507.428571   \n",
       "2022-01-10       -7.285714  9018.714286    175.571429       63.714286   \n",
       "2022-01-11      -50.000000  9028.142857      9.428571     -166.142857   \n",
       "2022-01-12     -128.285714  8877.000000   -151.142857     -160.571429   \n",
       "2022-01-13      131.142857  8490.428571   -386.571429     -235.428571   \n",
       "\n",
       "                test_VS  diff_test_VS  diff_2_test_VS     vac_all  \n",
       "datum                                                              \n",
       "2021-01-01   834.571429     20.142857       18.285714    0.044286  \n",
       "2021-01-02   864.285714     29.714286        9.571429    0.052857  \n",
       "2021-01-03   882.142857     17.857143      -11.857143    0.061429  \n",
       "2021-01-04   885.000000      2.857143      -15.000000    0.074286  \n",
       "2021-01-05   918.714286     33.714286       30.857143    0.095714  \n",
       "...                 ...           ...             ...         ...  \n",
       "2022-01-09  4036.571429     53.571429     -170.285714  162.535714  \n",
       "2022-01-10  4030.142857     -6.428571      -60.000000  163.337143  \n",
       "2022-01-11  3984.571429    -45.571429      -39.142857  164.125714  \n",
       "2022-01-12  3904.571429    -80.000000      -34.428571  164.895714  \n",
       "2022-01-13  3753.428571   -151.142857      -71.142857  165.647143  \n",
       "\n",
       "[378 rows x 73 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_GE.csv')\n",
    "df.set_index('datum', inplace = True)\n",
    "\n",
    "df.sort_index(inplace = True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.loc['2021-01-01':]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "723b1e27-d640-49ab-b9ce-8123d160a229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T17:49:35.692942Z",
     "iopub.status.busy": "2022-01-21T17:49:35.692423Z",
     "iopub.status.idle": "2022-01-21T17:49:35.713615Z",
     "shell.execute_reply": "2022-01-21T17:49:35.713098Z",
     "shell.execute_reply.started": "2022-01-21T17:49:35.692909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases_GE</th>\n",
       "      <th>diff_cases_GE</th>\n",
       "      <th>diff_2_cases_GE</th>\n",
       "      <th>hosp_GE</th>\n",
       "      <th>diff_hosp_GE</th>\n",
       "      <th>diff_2_hosp_GE</th>\n",
       "      <th>test_GE</th>\n",
       "      <th>diff_test_GE</th>\n",
       "      <th>diff_2_test_GE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>130.571429</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1515.428571</td>\n",
       "      <td>-28.142857</td>\n",
       "      <td>199.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>134.714286</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1480.714286</td>\n",
       "      <td>-34.714286</td>\n",
       "      <td>-6.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>134.142857</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-4.714286</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>1446.285714</td>\n",
       "      <td>-34.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>127.857143</td>\n",
       "      <td>-6.285714</td>\n",
       "      <td>-5.714286</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>1426.285714</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>14.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>124.857143</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>1441.428571</td>\n",
       "      <td>15.142857</td>\n",
       "      <td>35.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09</th>\n",
       "      <td>2443.428571</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-119.857143</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6920.285714</td>\n",
       "      <td>130.428571</td>\n",
       "      <td>-189.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>2520.571429</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>78.285714</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>7029.142857</td>\n",
       "      <td>108.857143</td>\n",
       "      <td>-21.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>2515.857143</td>\n",
       "      <td>-4.714286</td>\n",
       "      <td>-81.857143</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7106.714286</td>\n",
       "      <td>77.571429</td>\n",
       "      <td>-31.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>2475.142857</td>\n",
       "      <td>-40.714286</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>13.714286</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>7056.571429</td>\n",
       "      <td>-50.142857</td>\n",
       "      <td>-127.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>2330.000000</td>\n",
       "      <td>-145.142857</td>\n",
       "      <td>-104.428571</td>\n",
       "      <td>10.857143</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>-1.571429</td>\n",
       "      <td>6893.714286</td>\n",
       "      <td>-162.857143</td>\n",
       "      <td>-112.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cases_GE  diff_cases_GE  diff_2_cases_GE    hosp_GE  \\\n",
       "datum                                                                \n",
       "2021-01-01   130.571429       2.285714         3.714286   4.142857   \n",
       "2021-01-02   134.714286       4.142857         1.857143   4.571429   \n",
       "2021-01-03   134.142857      -0.571429        -4.714286   4.714286   \n",
       "2021-01-04   127.857143      -6.285714        -5.714286   4.571429   \n",
       "2021-01-05   124.857143      -3.000000         3.285714   4.285714   \n",
       "...                 ...            ...              ...        ...   \n",
       "2022-01-09  2443.428571      -1.142857      -119.857143  19.285714   \n",
       "2022-01-10  2520.571429      77.142857        78.285714  17.142857   \n",
       "2022-01-11  2515.857143      -4.714286       -81.857143  15.000000   \n",
       "2022-01-12  2475.142857     -40.714286       -36.000000  13.714286   \n",
       "2022-01-13  2330.000000    -145.142857      -104.428571  10.857143   \n",
       "\n",
       "            diff_hosp_GE  diff_2_hosp_GE      test_GE  diff_test_GE  \\\n",
       "datum                                                                 \n",
       "2021-01-01      0.142857        0.428571  1515.428571    -28.142857   \n",
       "2021-01-02      0.428571        0.285714  1480.714286    -34.714286   \n",
       "2021-01-03      0.142857       -0.285714  1446.285714    -34.428571   \n",
       "2021-01-04     -0.142857       -0.285714  1426.285714    -20.000000   \n",
       "2021-01-05     -0.285714       -0.142857  1441.428571     15.142857   \n",
       "...                  ...             ...          ...           ...   \n",
       "2022-01-09     -1.714286        0.285714  6920.285714    130.428571   \n",
       "2022-01-10     -2.142857       -0.428571  7029.142857    108.857143   \n",
       "2022-01-11     -2.142857        0.000000  7106.714286     77.571429   \n",
       "2022-01-12     -1.285714        0.857143  7056.571429    -50.142857   \n",
       "2022-01-13     -2.857143       -1.571429  6893.714286   -162.857143   \n",
       "\n",
       "            diff_2_test_GE  \n",
       "datum                       \n",
       "2021-01-01      199.285714  \n",
       "2021-01-02       -6.571429  \n",
       "2021-01-03        0.285714  \n",
       "2021-01-04       14.428571  \n",
       "2021-01-05       35.142857  \n",
       "...                    ...  \n",
       "2022-01-09     -189.428571  \n",
       "2022-01-10      -21.571429  \n",
       "2022-01-11      -31.285714  \n",
       "2022-01-12     -127.714286  \n",
       "2022-01-13     -112.714286  \n",
       "\n",
       "[378 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n = pd.DataFrame()\n",
    "\n",
    "for i in df.columns: \n",
    "    \n",
    "    if i.endswith('GE'):\n",
    "        \n",
    "        df_n[i] = df[i]\n",
    "\n",
    "#df_n['vac_all'] = df['vac_all']\n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1889326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T18:09:11.461499Z",
     "iopub.status.busy": "2022-01-21T18:09:11.461178Z",
     "iopub.status.idle": "2022-01-21T18:21:19.311421Z",
     "shell.execute_reply": "2022-01-21T18:21:19.310699Z",
     "shell.execute_reply.started": "2022-01-21T18:09:11.461471Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Compilation Time :  0.005809307098388672\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 14, 5)]           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 10)                1280      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                154       \n",
      "=================================================================\n",
      "Total params: 1,434\n",
      "Trainable params: 1,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 18:09:11.980421: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-01-21 18:09:11.980459: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-01-21 18:09:11.980523: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED\n",
      "2022-01-21 18:09:11.980541: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/228 [..............................] - ETA: 24s - loss: 0.0844 - accuracy: 0.0000e+00 - mape: 98.7464 - mse: 0.1157 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 18:09:14.493925: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-01-21 18:09:14.493987: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-01-21 18:09:14.494053: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/228 [>.............................] - ETA: 15s - loss: 0.0700 - accuracy: 0.0000e+00 - mape: 98.0385 - mse: 0.0945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 18:09:14.703712: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2022-01-21 18:09:14.730418: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-01-21 18:09:14.736550: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-01-21 18:09:14.739280: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./tensorboard/train/plugins/profile/2022_01_21_18_09_14\n",
      "2022-01-21 18:09:14.739815: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.trace.json.gz\n",
      "2022-01-21 18:09:14.774491: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./tensorboard/train/plugins/profile/2022_01_21_18_09_14\n",
      "2022-01-21 18:09:14.780184: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.memory_profile.json.gz\n",
      "2022-01-21 18:09:14.780643: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./tensorboard/train/plugins/profile/2022_01_21_18_09_14Dumped tool data for xplane.pb to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./tensorboard/train/plugins/profile/2022_01_21_18_09_14/j-eduar-tensorflow-170ddcbe30db4abd8b56da3e4e362ba9-7998cfr8qth.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 10s 34ms/step - loss: 0.0214 - accuracy: 0.0671 - mape: 1218921.3044 - mse: 0.0285 - val_loss: 0.0030 - val_accuracy: 0.0732 - val_mape: 62.4657 - val_mse: 0.0039\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0041 - accuracy: 0.0459 - mape: 2250146.1071 - mse: 0.0057 - val_loss: 0.0021 - val_accuracy: 0.2195 - val_mape: 48.7843 - val_mse: 0.0027\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0041 - accuracy: 0.0814 - mape: 1437247.1447 - mse: 0.0061 - val_loss: 0.0020 - val_accuracy: 0.0000e+00 - val_mape: 45.7104 - val_mse: 0.0025\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0033 - accuracy: 0.1045 - mape: 1930006.1507 - mse: 0.0046 - val_loss: 0.0021 - val_accuracy: 0.0732 - val_mape: 46.7267 - val_mse: 0.0027\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0035 - accuracy: 0.1221 - mape: 1179229.8370 - mse: 0.0050 - val_loss: 0.0026 - val_accuracy: 0.1951 - val_mape: 52.7441 - val_mse: 0.0034\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0027 - accuracy: 0.1191 - mape: 1102306.7101 - mse: 0.0038 - val_loss: 0.0031 - val_accuracy: 0.0000e+00 - val_mape: 54.8621 - val_mse: 0.0041\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0026 - accuracy: 0.1924 - mape: 1209428.6138 - mse: 0.0037 - val_loss: 0.0017 - val_accuracy: 0.0244 - val_mape: 36.9606 - val_mse: 0.0023\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0028 - accuracy: 0.1466 - mape: 690885.7758 - mse: 0.0041 - val_loss: 0.0022 - val_accuracy: 0.1220 - val_mape: 39.0595 - val_mse: 0.0030\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0029 - accuracy: 0.1353 - mape: 701021.6463 - mse: 0.0043 - val_loss: 0.0015 - val_accuracy: 0.0976 - val_mape: 34.0139 - val_mse: 0.0020\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0024 - accuracy: 0.1949 - mape: 1033456.7091 - mse: 0.0033 - val_loss: 0.0016 - val_accuracy: 0.1220 - val_mape: 34.6561 - val_mse: 0.0022\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0020 - accuracy: 0.1227 - mape: 928339.1621 - mse: 0.0029 - val_loss: 0.0020 - val_accuracy: 0.0488 - val_mape: 39.8421 - val_mse: 0.0026\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0023 - accuracy: 0.1407 - mape: 815120.6559 - mse: 0.0032 - val_loss: 0.0016 - val_accuracy: 0.0976 - val_mape: 34.9322 - val_mse: 0.0022\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0023 - accuracy: 0.1712 - mape: 774550.2291 - mse: 0.0035 - val_loss: 0.0016 - val_accuracy: 0.1951 - val_mape: 34.1628 - val_mse: 0.0021\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0021 - accuracy: 0.2332 - mape: 828555.4295 - mse: 0.0029 - val_loss: 0.0017 - val_accuracy: 0.0488 - val_mape: 31.8991 - val_mse: 0.0023\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0022 - accuracy: 0.1684 - mape: 664744.6204 - mse: 0.0032 - val_loss: 0.0020 - val_accuracy: 0.2683 - val_mape: 37.7650 - val_mse: 0.0026\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0022 - accuracy: 0.1769 - mape: 1033133.5000 - mse: 0.0033 - val_loss: 0.0026 - val_accuracy: 0.1220 - val_mape: 45.5352 - val_mse: 0.0035\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0026 - accuracy: 0.1591 - mape: 893462.2089 - mse: 0.0038 - val_loss: 0.0011 - val_accuracy: 0.0488 - val_mape: 25.6542 - val_mse: 0.0015\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0023 - accuracy: 0.1444 - mape: 538945.6984 - mse: 0.0034 - val_loss: 0.0012 - val_accuracy: 0.2927 - val_mape: 28.2091 - val_mse: 0.0016\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0017 - accuracy: 0.1614 - mape: 799829.3737 - mse: 0.0024 - val_loss: 0.0019 - val_accuracy: 0.1220 - val_mape: 35.4517 - val_mse: 0.0026\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0021 - accuracy: 0.1665 - mape: 881977.5179 - mse: 0.0030 - val_loss: 0.0017 - val_accuracy: 0.0244 - val_mape: 34.7706 - val_mse: 0.0023\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0019 - accuracy: 0.1123 - mape: 907898.5136 - mse: 0.0028 - val_loss: 0.0015 - val_accuracy: 0.1707 - val_mape: 31.3380 - val_mse: 0.0019\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0020 - accuracy: 0.1247 - mape: 809704.5647 - mse: 0.0029 - val_loss: 0.0014 - val_accuracy: 0.1951 - val_mape: 31.1599 - val_mse: 0.0018\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0021 - accuracy: 0.1210 - mape: 1021265.5317 - mse: 0.0032 - val_loss: 0.0015 - val_accuracy: 0.0244 - val_mape: 32.4553 - val_mse: 0.0019\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0022 - accuracy: 0.1457 - mape: 1172208.5976 - mse: 0.0033 - val_loss: 0.0016 - val_accuracy: 0.1220 - val_mape: 32.7766 - val_mse: 0.0021\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0021 - accuracy: 0.1669 - mape: 808459.3438 - mse: 0.0030 - val_loss: 0.0011 - val_accuracy: 0.0976 - val_mape: 28.0581 - val_mse: 0.0015\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0025 - accuracy: 0.1339 - mape: 723575.4565 - mse: 0.0038 - val_loss: 0.0010 - val_accuracy: 0.2927 - val_mape: 26.5642 - val_mse: 0.0014\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0022 - accuracy: 0.1963 - mape: 559547.9336 - mse: 0.0033 - val_loss: 9.9723e-04 - val_accuracy: 0.2927 - val_mape: 25.7448 - val_mse: 0.0013\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0019 - accuracy: 0.1573 - mape: 593672.6400 - mse: 0.0028 - val_loss: 0.0013 - val_accuracy: 0.2195 - val_mape: 29.6543 - val_mse: 0.0018\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0020 - accuracy: 0.1898 - mape: 667471.7148 - mse: 0.0029 - val_loss: 0.0021 - val_accuracy: 0.0244 - val_mape: 40.0618 - val_mse: 0.0027\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0022 - accuracy: 0.1048 - mape: 667879.4325 - mse: 0.0032 - val_loss: 0.0020 - val_accuracy: 0.2439 - val_mape: 39.4697 - val_mse: 0.0026\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0020 - accuracy: 0.1598 - mape: 1015771.4831 - mse: 0.0031 - val_loss: 0.0012 - val_accuracy: 0.0244 - val_mape: 27.9498 - val_mse: 0.0016\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0016 - accuracy: 0.1477 - mape: 838685.7298 - mse: 0.0024 - val_loss: 0.0012 - val_accuracy: 0.2195 - val_mape: 26.5611 - val_mse: 0.0015\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0018 - accuracy: 0.1800 - mape: 1017709.9559 - mse: 0.0027 - val_loss: 9.7283e-04 - val_accuracy: 0.2683 - val_mape: 24.4264 - val_mse: 0.0013\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0017 - accuracy: 0.1524 - mape: 745178.6429 - mse: 0.0024 - val_loss: 0.0012 - val_accuracy: 0.1707 - val_mape: 27.8349 - val_mse: 0.0016\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0018 - accuracy: 0.2554 - mape: 865842.3946 - mse: 0.0026 - val_loss: 0.0012 - val_accuracy: 0.1707 - val_mape: 31.5842 - val_mse: 0.0016\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0018 - accuracy: 0.1509 - mape: 756338.5276 - mse: 0.0026 - val_loss: 0.0011 - val_accuracy: 0.2927 - val_mape: 26.5215 - val_mse: 0.0015\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0016 - accuracy: 0.2317 - mape: 734274.3547 - mse: 0.0023 - val_loss: 0.0012 - val_accuracy: 0.3171 - val_mape: 28.4415 - val_mse: 0.0015\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0018 - accuracy: 0.2377 - mape: 751739.8345 - mse: 0.0026 - val_loss: 0.0010 - val_accuracy: 0.0488 - val_mape: 25.1272 - val_mse: 0.0014\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0017 - accuracy: 0.1727 - mape: 670149.6005 - mse: 0.0024 - val_loss: 0.0016 - val_accuracy: 0.1707 - val_mape: 32.4561 - val_mse: 0.0020\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0015 - accuracy: 0.1485 - mape: 541703.6636 - mse: 0.0023 - val_loss: 0.0012 - val_accuracy: 0.2683 - val_mape: 29.3777 - val_mse: 0.0016\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0016 - accuracy: 0.1287 - mape: 566187.8573 - mse: 0.0024 - val_loss: 0.0015 - val_accuracy: 0.2439 - val_mape: 32.3040 - val_mse: 0.0020\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0015 - accuracy: 0.2049 - mape: 610807.8497 - mse: 0.0022 - val_loss: 0.0012 - val_accuracy: 0.1951 - val_mape: 30.1066 - val_mse: 0.0016\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0018 - accuracy: 0.1651 - mape: 595650.4408 - mse: 0.0026 - val_loss: 0.0010 - val_accuracy: 0.3415 - val_mape: 26.9989 - val_mse: 0.0013\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 0.0016 - accuracy: 0.2655 - mape: 884183.5577 - mse: 0.0022 - val_loss: 0.0011 - val_accuracy: 0.4146 - val_mape: 27.4081 - val_mse: 0.0015\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0019 - accuracy: 0.2100 - mape: 804620.5336 - mse: 0.0029 - val_loss: 0.0011 - val_accuracy: 0.2439 - val_mape: 27.9901 - val_mse: 0.0015\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0019 - accuracy: 0.1762 - mape: 731088.9892 - mse: 0.0029 - val_loss: 0.0011 - val_accuracy: 0.3415 - val_mape: 28.2722 - val_mse: 0.0014\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0016 - accuracy: 0.2074 - mape: 669837.5306 - mse: 0.0024 - val_loss: 0.0011 - val_accuracy: 0.2927 - val_mape: 26.3820 - val_mse: 0.0015\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.0019 - accuracy: 0.2437 - mape: 632077.3412 - mse: 0.0028 - val_loss: 0.0013 - val_accuracy: 0.2683 - val_mape: 30.9086 - val_mse: 0.0017\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.0976 - mape: 41.2145 - mse: 0.0945\n",
      "[0.026549050584435463, 0.09756097197532654, 41.21449661254883, 0.09451024234294891]\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.0265 - accuracy: 0.0610 - mape: 41.3905 - mse: 0.0933\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 12ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 12ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 12ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 12ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "82/82 [==============================] - 1s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step - loss: 0.0016 - accuracy: 0.2007 - mape: 613932.3750 - mse: 0.0023\n",
      "[0.0016253228532150388, 0.20074349641799927, 613932.375, 0.0023313509300351143]\n",
      "269/269 [==============================] - 3s 12ms/step - loss: 0.0016 - accuracy: 0.1747 - mape: 611937.4375 - mse: 0.0023\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "269/269 [==============================] - 3s 11ms/step\n",
      "CPU times: user 13min 48s, sys: 49.5 s, total: 14min 38s\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted, X_train, X_test, Y_test, Y_train, factor = train_evaluate_model(target_name = 'hosp_GE', data = df_n[['hosp_GE', 'diff_hosp_GE', 'diff_2_hosp_GE', 'cases_GE', 'diff_cases_GE']],\n",
    "predict_n = 14, look_back = 14, hidden = 10, epochs = 100, ratio=0.75, cluster=True, load=False,\n",
    "                         uncertainty= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aa558e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T18:21:19.317430Z",
     "iopub.status.busy": "2022-01-21T18:21:19.317204Z",
     "iopub.status.idle": "2022-01-21T18:21:19.798420Z",
     "shell.execute_reply": "2022-01-21T18:21:19.796676Z",
     "shell.execute_reply.started": "2022-01-21T18:21:19.317409Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indice = list(df.index)\n",
    "indice = [i.date() for i in indice]\n",
    "    \n",
    "plot_predicted_vs_data(\n",
    "        predicted,\n",
    "        np.concatenate((Y_train, Y_test), axis=0),\n",
    "        indice[:],\n",
    "        label=\"{}\".format('hosp_GE'),\n",
    "        pred_window=14,\n",
    "        factor=factor,\n",
    "        split_point=len(Y_train),\n",
    "        uncertainty= False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24373dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca50078-e1fe-4be8-9af8-17f7ce6a9c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f27cdd-9508-4f98-9eaf-0ee75b398727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
